{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sangithajk/Hackathon/blob/master/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuagMBSaAbtT",
        "colab_type": "code",
        "outputId": "3f3318a4-eb49-4517-f35b-61496482bb14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a360IxLNAzHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv(\"/content/drive/My Drive/review_train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/My Drive/review_test.csv\")\n",
        "train[\"source\"] = \"train\"\n",
        "test[\"source\"] = \"test\"\n",
        "dataset = pd.concat([train,test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7OXGEJNBrwl",
        "colab_type": "code",
        "outputId": "86dfa1f0-590d-4264-dd3a-85ee22c6abdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz1GfeMIBuKp",
        "colab_type": "code",
        "outputId": "3abb7d7c-93a9-47b8-ef20-ec94f8d63493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I got a free sample of these once, and now--we...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I used to get this Tea when I lived in Washing...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is my all time favorite 'grab and go' sna...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This flavor is very good and unexpected.  The ...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>thrilled to have this assortment as i got the ...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Score  Sentiment source\n",
              "0  I got a free sample of these once, and now--we...      5          1  train\n",
              "1  I used to get this Tea when I lived in Washing...      4          1  train\n",
              "2  This is my all time favorite 'grab and go' sna...      5          1  train\n",
              "3  This flavor is very good and unexpected.  The ...      4          1  train\n",
              "4  thrilled to have this assortment as i got the ...      4          1  train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6pCa58OC9yx",
        "colab_type": "code",
        "outputId": "a44df5ed-42ef-4a6b-bc38-efeab97b66e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18532, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3_H1GXhHzCw",
        "colab_type": "code",
        "outputId": "232a32e9-62dd-4863-bfb1-171cc1dfbdb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "dataset.Sentiment.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    15637\n",
              "0     2895\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3m3_srJECwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build train and test datasets\n",
        "reviews = dataset['Text'].values\n",
        "sentiments = dataset['Sentiment'].values\n",
        "\n",
        "train_reviews = train['Text'].values\n",
        "train_sentiments = train['Sentiment'].values\n",
        "\n",
        "test_reviews = test['Text'].values\n",
        "test_sentiments = test['Sentiment'].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcf9t9MjGB6i",
        "colab_type": "code",
        "outputId": "3bed8ec5-ed9a-4899-cdc3-80e48fb4aed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip install contractions\n",
        "!pip install textsearch\n",
        "!pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.21)\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (0.0.17)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch) (1.4.0)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch) (1.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnHDzdPVFdVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import contractions\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import re\n",
        "import tqdm\n",
        "import unicodedata\n",
        "\n",
        "\n",
        "def strip_html_tags(text):\n",
        "  soup = BeautifulSoup(text, \"html.parser\")\n",
        "  [s.extract() for s in soup(['iframe', 'script'])]\n",
        "  stripped_text = soup.get_text()\n",
        "  stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
        "  return stripped_text\n",
        "\n",
        "def remove_accented_chars(text):\n",
        "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "  return text\n",
        "\n",
        "def pre_process_corpus(docs):\n",
        "  norm_docs = []\n",
        "  for doc in tqdm.tqdm(docs):\n",
        "    doc = strip_html_tags(doc)\n",
        "    doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
        "    doc = doc.lower()\n",
        "    doc = remove_accented_chars(doc)\n",
        "    doc = contractions.fix(doc)\n",
        "    # lower case and remove special characters\\whitespaces\n",
        "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
        "    doc = re.sub(' +', ' ', doc)\n",
        "    doc = doc.strip()  \n",
        "    norm_docs.append(doc)\n",
        "  \n",
        "  return norm_docs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFspbS9BGJgf",
        "colab_type": "code",
        "outputId": "bb13c6b5-3d7f-4264-db4d-5da88341f105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "norm_train_reviews = pre_process_corpus(train_reviews)\n",
        "norm_test_reviews = pre_process_corpus(test_reviews)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14825/14825 [00:03<00:00, 4368.40it/s]\n",
            "100%|██████████| 3707/3707 [00:00<00:00, 4414.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.21 s, sys: 40 ms, total: 4.25 s\n",
            "Wall time: 4.25 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFA2xSv9GRlV",
        "colab_type": "code",
        "outputId": "fffdb77f-cf83-4937-94af-2c78a835afa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# build BOW features on train reviews\n",
        "cv = CountVectorizer(binary=False, min_df=5, max_df=1.0, ngram_range=(1,2))\n",
        "cv_train_features = cv.fit_transform(norm_train_reviews)\n",
        "\n",
        "\n",
        "# build TFIDF features on train reviews\n",
        "tv = TfidfVectorizer(use_idf=True, min_df=5, max_df=1.0, ngram_range=(1,2),\n",
        "                     sublinear_tf=True)\n",
        "tv_train_features = tv.fit_transform(norm_train_reviews)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.9 s, sys: 131 ms, total: 7.03 s\n",
            "Wall time: 7.05 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DICfkZwkGbiA",
        "colab_type": "code",
        "outputId": "89e4cf1c-d123-4a8b-daa4-af2e0c55edfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# transform test reviews into features\n",
        "cv_test_features = cv.transform(norm_test_reviews)\n",
        "tv_test_features = tv.transform(norm_test_reviews)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 934 ms, sys: 377 µs, total: 934 ms\n",
            "Wall time: 939 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY6I1fZ0GiMm",
        "colab_type": "code",
        "outputId": "06d64ef5-6b72-4101-df82-862d7eeedc6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\n",
        "print('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BOW model:> Train features shape: (14825, 36702)  Test features shape: (3707, 36702)\n",
            "TFIDF model:> Train features shape: (14825, 36702)  Test features shape: (3707, 36702)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZusXq8VkRRt",
        "colab_type": "code",
        "outputId": "71560c5b-e243-403a-c4ba-3b2427efb66e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "cv_train_features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<14825x36702 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 1386660 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly3RPIrJG39i",
        "colab_type": "code",
        "outputId": "a2b4fd0f-dd14-435b-a93e-4950ce7e2aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# Logistic Regression model on BOW features\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# instantiate model\n",
        "lr = LogisticRegression(penalty='l2', max_iter=500, C=1, solver='lbfgs', random_state=42)\n",
        "\n",
        "# train model\n",
        "lr.fit(cv_train_features, train_sentiments)\n",
        "\n",
        "# predict on test data\n",
        "lr_bow_predictions = lr.predict(cv_test_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.93 s, sys: 2.95 s, total: 6.89 s\n",
            "Wall time: 3.54 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf7-bgVcG6a_",
        "colab_type": "code",
        "outputId": "d34dc74f-39da-40d0-f719-c092f0685f30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "print(classification_report(test_sentiments, lr_bow_predictions))\n",
        "pd.DataFrame(confusion_matrix(test_sentiments, lr_bow_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.68      0.75       592\n",
            "           1       0.94      0.97      0.96      3115\n",
            "\n",
            "    accuracy                           0.93      3707\n",
            "   macro avg       0.89      0.83      0.85      3707\n",
            "weighted avg       0.92      0.93      0.92      3707\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>404</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>79</td>\n",
              "      <td>3036</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0     1\n",
              "0  404   188\n",
              "1   79  3036"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogkEutNrHPUd",
        "colab_type": "code",
        "outputId": "31d26ee3-ffae-4d0f-880a-baa3102308bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# Random Forest model on BOW features\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# instantiate model\n",
        "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
        "\n",
        "# train model\n",
        "rf.fit(cv_train_features, train_sentiments)\n",
        "\n",
        "# predict on test data\n",
        "rf_bow_predictions = rf.predict(cv_test_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 24.9 s, sys: 27.8 ms, total: 24.9 s\n",
            "Wall time: 12.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTdEOV5OIZln",
        "colab_type": "code",
        "outputId": "491c0f1f-7b3e-481d-983f-c954aea55f15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "print(classification_report(test_sentiments, rf_bow_predictions))\n",
        "pd.DataFrame(confusion_matrix(test_sentiments, rf_bow_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.17      0.29       592\n",
            "           1       0.86      1.00      0.93      3115\n",
            "\n",
            "    accuracy                           0.87      3707\n",
            "   macro avg       0.93      0.59      0.61      3707\n",
            "weighted avg       0.88      0.87      0.83      3707\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>102</td>\n",
              "      <td>490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0     1\n",
              "0  102   490\n",
              "1    1  3114"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30Uuo6YXKH-8",
        "colab_type": "code",
        "outputId": "4a17bc64-2550-4b29-8ea3-01dea9b394d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# Random Forest model on TF-IDF features\n",
        "\n",
        "# train model\n",
        "rf.fit(tv_train_features, train_sentiments)\n",
        "\n",
        "# predict on test data\n",
        "rf_tfidf_predictions = rf.predict(tv_test_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 28.4 s, sys: 12.1 ms, total: 28.4 s\n",
            "Wall time: 14.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAjHAqF1KQJw",
        "colab_type": "code",
        "outputId": "47a962ce-76f5-4387-b15c-5cda41a55f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "\n",
        "print(classification_report(test_sentiments, rf_tfidf_predictions))\n",
        "pd.DataFrame(confusion_matrix(test_sentiments, rf_tfidf_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.20      0.33       592\n",
            "           1       0.87      1.00      0.93      3115\n",
            "\n",
            "    accuracy                           0.87      3707\n",
            "   macro avg       0.92      0.60      0.63      3707\n",
            "weighted avg       0.88      0.87      0.83      3707\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>119</td>\n",
              "      <td>473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>3111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0     1\n",
              "0  119   473\n",
              "1    4  3111"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrNcpMiHKgqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Activation, Dense\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W4gQEsfKpYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "# tokenize train reviews & encode train labels\n",
        "tokenized_train = [nltk.word_tokenize(text)\n",
        "                       for text in norm_train_reviews]\n",
        "y_train = le.fit_transform(train_sentiments)\n",
        "# tokenize test reviews & encode test labels\n",
        "tokenized_test = [nltk.word_tokenize(text)\n",
        "                       for text in norm_test_reviews]\n",
        "y_test = le.fit_transform(test_sentiments)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qme0HdhFKwpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwpo4fBSK5ly",
        "colab_type": "code",
        "outputId": "ca491ff9-0437-4890-e906-0f33c9b803ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "# build word2vec model\n",
        "w2v_num_features = 300\n",
        "w2v_model = gensim.models.Word2Vec(tokenized_train, size=w2v_num_features, window=150,\n",
        "                                   min_count=10, workers=4, iter=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-09-18 05:25:39,599 : INFO : collecting all words and their counts\n",
            "2019-09-18 05:25:39,600 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2019-09-18 05:25:39,758 : INFO : PROGRESS: at sentence #10000, processed 786775 words, keeping 29049 word types\n",
            "2019-09-18 05:25:39,839 : INFO : collected 36775 word types from a corpus of 1167142 raw words and 14825 sentences\n",
            "2019-09-18 05:25:39,840 : INFO : Loading a fresh vocabulary\n",
            "2019-09-18 05:25:40,170 : INFO : effective_min_count=10 retains 5110 unique words (13% of original 36775, drops 31665)\n",
            "2019-09-18 05:25:40,171 : INFO : effective_min_count=10 leaves 1107625 word corpus (94% of original 1167142, drops 59517)\n",
            "2019-09-18 05:25:40,194 : INFO : deleting the raw counts dictionary of 36775 items\n",
            "2019-09-18 05:25:40,197 : INFO : sample=0.001 downsamples 57 most-common words\n",
            "2019-09-18 05:25:40,198 : INFO : downsampling leaves estimated 790586 word corpus (71.4% of prior 1107625)\n",
            "2019-09-18 05:25:40,221 : INFO : estimated required memory for 5110 words and 300 dimensions: 14819000 bytes\n",
            "2019-09-18 05:25:40,222 : INFO : resetting layer weights\n",
            "2019-09-18 05:25:40,287 : INFO : training model with 4 workers on 5110 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=150\n",
            "2019-09-18 05:25:41,401 : INFO : EPOCH 1 - PROGRESS: at 16.61% examples, 115081 words/s, in_qsize 8, out_qsize 0\n",
            "2019-09-18 05:25:42,410 : INFO : EPOCH 1 - PROGRESS: at 32.63% examples, 120335 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:25:43,419 : INFO : EPOCH 1 - PROGRESS: at 48.82% examples, 122407 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:25:44,513 : INFO : EPOCH 1 - PROGRESS: at 65.65% examples, 122623 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:25:45,514 : INFO : EPOCH 1 - PROGRESS: at 81.69% examples, 123602 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:25:46,575 : INFO : EPOCH 1 - PROGRESS: at 97.63% examples, 122634 words/s, in_qsize 3, out_qsize 1\n",
            "2019-09-18 05:25:46,577 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-18 05:25:46,592 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-18 05:25:46,602 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-18 05:25:46,612 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-18 05:25:46,613 : INFO : EPOCH - 1 : training on 1167142 raw words (790234 effective words) took 6.3s, 125068 effective words/s\n",
            "2019-09-18 05:25:47,643 : INFO : EPOCH 2 - PROGRESS: at 15.78% examples, 117701 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:25:48,697 : INFO : EPOCH 2 - PROGRESS: at 31.73% examples, 119323 words/s, in_qsize 8, out_qsize 0\n",
            "2019-09-18 05:25:49,761 : INFO : EPOCH 2 - PROGRESS: at 48.82% examples, 121819 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:25:50,857 : INFO : EPOCH 2 - PROGRESS: at 65.65% examples, 122178 words/s, in_qsize 8, out_qsize 0\n",
            "2019-09-18 05:25:51,865 : INFO : EPOCH 2 - PROGRESS: at 81.79% examples, 123023 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:25:52,802 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-18 05:25:52,888 : INFO : EPOCH 2 - PROGRESS: at 98.70% examples, 124385 words/s, in_qsize 2, out_qsize 1\n",
            "2019-09-18 05:25:52,891 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-18 05:25:52,906 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-18 05:25:52,909 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-18 05:25:52,910 : INFO : EPOCH - 2 : training on 1167142 raw words (790749 effective words) took 6.3s, 125662 effective words/s\n",
            "2019-09-18 05:25:53,956 : INFO : EPOCH 3 - PROGRESS: at 15.78% examples, 115844 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:25:54,995 : INFO : EPOCH 3 - PROGRESS: at 31.73% examples, 119318 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:25:56,003 : INFO : EPOCH 3 - PROGRESS: at 48.05% examples, 121890 words/s, in_qsize 7, out_qsize 1\n",
            "2019-09-18 05:25:57,027 : INFO : EPOCH 3 - PROGRESS: at 63.14% examples, 121015 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:25:58,059 : INFO : EPOCH 3 - PROGRESS: at 80.01% examples, 122888 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:25:59,108 : INFO : EPOCH 3 - PROGRESS: at 96.19% examples, 122715 words/s, in_qsize 5, out_qsize 0\n",
            "2019-09-18 05:25:59,190 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-18 05:25:59,237 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-18 05:25:59,253 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-18 05:25:59,262 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-18 05:25:59,263 : INFO : EPOCH - 3 : training on 1167142 raw words (790922 effective words) took 6.3s, 124579 effective words/s\n",
            "2019-09-18 05:26:00,296 : INFO : EPOCH 4 - PROGRESS: at 15.78% examples, 117499 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:26:01,323 : INFO : EPOCH 4 - PROGRESS: at 31.73% examples, 120901 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:26:02,375 : INFO : EPOCH 4 - PROGRESS: at 48.82% examples, 123262 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:26:03,446 : INFO : EPOCH 4 - PROGRESS: at 65.65% examples, 123982 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:26:04,452 : INFO : EPOCH 4 - PROGRESS: at 81.79% examples, 124521 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:26:05,429 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-18 05:26:05,476 : INFO : EPOCH 4 - PROGRESS: at 98.72% examples, 125633 words/s, in_qsize 2, out_qsize 1\n",
            "2019-09-18 05:26:05,481 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-18 05:26:05,503 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-18 05:26:05,513 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-18 05:26:05,515 : INFO : EPOCH - 4 : training on 1167142 raw words (790175 effective words) took 6.2s, 126559 effective words/s\n",
            "2019-09-18 05:26:06,632 : INFO : EPOCH 5 - PROGRESS: at 16.61% examples, 114557 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:26:07,678 : INFO : EPOCH 5 - PROGRESS: at 33.50% examples, 121237 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:26:08,705 : INFO : EPOCH 5 - PROGRESS: at 49.75% examples, 122369 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:26:09,730 : INFO : EPOCH 5 - PROGRESS: at 65.65% examples, 123055 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:26:10,778 : INFO : EPOCH 5 - PROGRESS: at 81.79% examples, 122813 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 05:26:11,710 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-18 05:26:11,780 : INFO : EPOCH 5 - PROGRESS: at 98.70% examples, 124645 words/s, in_qsize 2, out_qsize 1\n",
            "2019-09-18 05:26:11,783 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-18 05:26:11,787 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-18 05:26:11,795 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-18 05:26:11,796 : INFO : EPOCH - 5 : training on 1167142 raw words (790854 effective words) took 6.3s, 126032 effective words/s\n",
            "2019-09-18 05:26:11,797 : INFO : training on a 5835710 raw words (3952934 effective words) took 31.5s, 125454 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 2s, sys: 53.7 ms, total: 1min 2s\n",
            "Wall time: 32.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0pe5OQBLca0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def averaged_word2vec_vectorizer(corpus, model, num_features):\n",
        "    vocabulary = set(model.wv.index2word)\n",
        "    \n",
        "    def average_word_vectors(words, model, vocabulary, num_features):\n",
        "        feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
        "        nwords = 0.\n",
        "        \n",
        "        for word in words:\n",
        "            if word in vocabulary: \n",
        "                nwords = nwords + 1.\n",
        "                feature_vector = np.add(feature_vector, model.wv[word])\n",
        "        if nwords:\n",
        "            feature_vector = np.divide(feature_vector, nwords)\n",
        "\n",
        "        return feature_vector\n",
        "\n",
        "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
        "                    for tokenized_sentence in corpus]\n",
        "    return np.array(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPInoY6LM1ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate averaged word vector features from word2vec model\n",
        "avg_wv_train_features = averaged_word2vec_vectorizer(corpus=tokenized_train, model=w2v_model,\n",
        "                                                     num_features=w2v_num_features)\n",
        "avg_wv_test_features = averaged_word2vec_vectorizer(corpus=tokenized_test, model=w2v_model,\n",
        "                                                    num_features=w2v_num_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHFVCxuLNODI",
        "colab_type": "code",
        "outputId": "7ace0399-cacc-47d0-985a-490f80f68747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Word2Vec model:> Train features shape:', avg_wv_train_features.shape, ' Test features shape:', avg_wv_test_features.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec model:> Train features shape: (14825, 300)  Test features shape: (3707, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LWf4LIQNR71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def construct_deepnn_architecture(num_input_features):\n",
        "    dnn_model = Sequential()\n",
        "    dnn_model.add(Dense(512, input_shape=(num_input_features,)))\n",
        "    dnn_model.add(Activation('relu'))\n",
        "    dnn_model.add(Dropout(0.2))\n",
        "    \n",
        "    dnn_model.add(Dense(256))\n",
        "    dnn_model.add(Activation('relu'))\n",
        "    dnn_model.add(Dropout(0.2))\n",
        "    \n",
        "    dnn_model.add(Dense(256))\n",
        "    dnn_model.add(Activation('relu'))\n",
        "    dnn_model.add(Dropout(0.2))\n",
        "    \n",
        "    dnn_model.add(Dense(1))\n",
        "    dnn_model.add(Activation('sigmoid'))\n",
        "\n",
        "    dnn_model.compile(loss='binary_crossentropy', optimizer='adam',                 \n",
        "                      metrics=['accuracy'])\n",
        "    return dnn_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncYf8izcNZmS",
        "colab_type": "code",
        "outputId": "98c18238-a175-49b9-fe9c-89d70eb0f457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "w2v_dnn = construct_deepnn_architecture(num_input_features=w2v_num_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-18 05:26:16,786 : WARNING : From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-18 05:26:16,990 : WARNING : From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM68V5edNdyq",
        "colab_type": "code",
        "outputId": "053252ba-1271-4bd1-87e5-f1534a8cc9fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "w2v_dnn.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               154112    \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 351,489\n",
            "Trainable params: 351,489\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1_0b3-GNd-q",
        "colab_type": "code",
        "outputId": "513fea2a-2df4-4c34-b979-9c40098272a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "batch_size = 100\n",
        "w2v_dnn.fit(avg_wv_train_features, y_train, epochs=10, batch_size=batch_size, \n",
        "            shuffle=True, validation_split=0.1, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13342 samples, validate on 1483 samples\n",
            "Epoch 1/10\n",
            "13342/13342 [==============================] - 2s 155us/sample - loss: 0.3252 - acc: 0.8626 - val_loss: 0.2985 - val_acc: 0.8806\n",
            "Epoch 2/10\n",
            "13342/13342 [==============================] - 1s 111us/sample - loss: 0.2956 - acc: 0.8742 - val_loss: 0.2996 - val_acc: 0.8746\n",
            "Epoch 3/10\n",
            "13342/13342 [==============================] - 1s 109us/sample - loss: 0.2859 - acc: 0.8766 - val_loss: 0.2962 - val_acc: 0.8780\n",
            "Epoch 4/10\n",
            "13342/13342 [==============================] - 1s 112us/sample - loss: 0.2809 - acc: 0.8786 - val_loss: 0.2881 - val_acc: 0.8773\n",
            "Epoch 5/10\n",
            "13342/13342 [==============================] - 1s 107us/sample - loss: 0.2784 - acc: 0.8793 - val_loss: 0.2803 - val_acc: 0.8780\n",
            "Epoch 6/10\n",
            "13342/13342 [==============================] - 1s 108us/sample - loss: 0.2703 - acc: 0.8829 - val_loss: 0.2853 - val_acc: 0.8773\n",
            "Epoch 7/10\n",
            "13342/13342 [==============================] - 1s 111us/sample - loss: 0.2681 - acc: 0.8841 - val_loss: 0.2879 - val_acc: 0.8780\n",
            "Epoch 8/10\n",
            "13342/13342 [==============================] - 1s 106us/sample - loss: 0.2634 - acc: 0.8852 - val_loss: 0.2910 - val_acc: 0.8773\n",
            "Epoch 9/10\n",
            "13342/13342 [==============================] - 1s 106us/sample - loss: 0.2584 - acc: 0.8883 - val_loss: 0.2896 - val_acc: 0.8753\n",
            "Epoch 10/10\n",
            "13342/13342 [==============================] - 1s 109us/sample - loss: 0.2514 - acc: 0.8882 - val_loss: 0.2856 - val_acc: 0.8813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7585519470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okQ06YwLNd9g",
        "colab_type": "code",
        "outputId": "9105931d-63d8-4003-d4c4-8317857959f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "y_pred = w2v_dnn.predict_classes(avg_wv_test_features)\n",
        "predictions = le.inverse_transform(y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:273: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrAswD7vNxWx",
        "colab_type": "code",
        "outputId": "a89068a7-4c75-4d96-99f3-4d6c5227bd3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "\n",
        "print(classification_report(test_sentiments, predictions))\n",
        "pd.DataFrame(confusion_matrix(test_sentiments, predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.54      0.58       592\n",
            "           1       0.92      0.94      0.93      3115\n",
            "\n",
            "    accuracy                           0.88      3707\n",
            "   macro avg       0.77      0.74      0.76      3707\n",
            "weighted avg       0.87      0.88      0.87      3707\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>321</td>\n",
              "      <td>271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>185</td>\n",
              "      <td>2930</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0     1\n",
              "0  321   271\n",
              "1  185  2930"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    }
  ]
}